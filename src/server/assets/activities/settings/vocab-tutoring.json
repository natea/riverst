{
  "title": "Vocabulary Tutoring",
  "description": "Schema for configuring KIVA's vocabulary tutoring activity.",
  "type": "object",
  "properties": {
    "name": {
      "type": "string",
      "const": "vocab-tutoring"
    },
    "description": {
      "type": "string",
      "const": "Vocabulary tutoring activity with KIVA."
    },
    "options": {
      "type": "object",
      "properties": {
        "advanced_flows": {
          "type": "boolean",
          "const": true,
          "default": true,
          "description": "This activity requires advanced flows."
        },
        "advanced_flows_config_path": {
          "type": "string",
          "const": "./assets/activities/flows/vocab-tutoring.json",
          "default": "./assets/activities/flows/vocab-tutoring.json",
          "description": "Path to the advanced flows configuration file."
        },
        "pipeline_modality": {
          "type": "string",
          "enum": ["classic", "e2e"],
          "default": "classic",
          "const": "classic",
          "description": "The modality of the pipeline. This is set to 'classic' for the stt, llm and tts pipeline. Pipecat-flows doesn't support e2e mode yet."
        },
        "llm_type": {
          "type": "string",
          "enum": ["openai", "llama3.2"],
          "default": "openai",
          "description": "The LLM service to use."
        },
        "stt_type": {
          "type": "string",
          "enum": ["whisper", "openai"],
          "default": "openai",
          "description": "The STT service to use."
        },
        "tts_type": {
          "type": "string",
          "enum": ["openai", "piper"],
          "default": "openai",
          "description": "The TTS service to use."
        },
        "body_animations": {
          "type": "array",
          "items": {
            "type": "string",
            "enum": ["wave", "dance", "i_dont_know"]
          },
          "default": ["wave", "dance", "i_dont_know"],
          "description": "List of body animations that the avatar can perform."
        },
        "camera_settings": {
          "type": "string",
          "enum": ["half_body", "headshot", "full_body"],
          "default": "half_body",
          "description": "Select the camera framing used for the avatar during the interaction."
        },
        "user_description": {
          "type": "string",
          "maxLength": 500,
          "default": "A 3rd or 4th grader.",
          "description": "Optional free-text field to describe the user."
        },
        "video_flag": {
          "type": "boolean",
          "default": false,
          "description": "Enable or disable video processing during the session."
        },
        "video_out_width": {
          "type": "integer",
          "const": 640,
          "default": 640,
          "description": "Width of the video output in pixels."
        },
        "video_out_height": {
          "type": "integer",
          "const": 320,
          "default": 320,
          "description": "Height of the video output in pixels."
        },
        "video_out_framerate": {
          "type": "integer",
          "const": 30,
          "default": 30,
          "description": "Framerate of the video output in frames per second."
        },
        "user_transcript": {
          "type": "boolean",
          "default": false,
          "description": "Enable showing the transcript of the user’s speech. This only works with the classic pipeline modality."
        },
        "bot_transcript": {
          "type": "boolean",
          "default": false,
          "description": "Enable showing the transcript of the avatar’s speech."
        }
      },
      "required": [
        "advanced_flows",
        "advanced_flows_config_path",
        "camera_settings",
        "task_description",
        "avatar_personality_description",
        "avatar_system_prompt",
        "video_flag",
        "user_transcript",
        "bot_transcript"
      ]
    }
  },
  "required": ["name", "description", "options"]
}
