import {
  RTVIClientAudio,
  useRTVIClientTransportState,
  useRTVIClientEvent,
  useRTVIClient,
} from '@pipecat-ai/client-react';
import { RTVIEvent, Participant } from '@pipecat-ai/client-js';
import { RTVIProvider } from '../providers/RTVIProvider';
import AvatarRenderer from '../components/AvatarRenderer';
import SettingsForm from '../components/SettingsForm';
import './AvatarInteraction.css';

import { useEffect, useState, useCallback, useRef } from 'react';
import { useLocation, useNavigate } from 'react-router-dom';
import { Button, FloatButton, Popconfirm, Typography } from 'antd';
import { PoweroffOutlined, LoadingOutlined } from '@ant-design/icons';
import axios from 'axios';

const { Text } = Typography;

const SubtitleOverlay = ({ subtitles }: { subtitles: { id: number; text: string; speaker: 'user' | 'bot' }[] }) => (
  <div style={{
    position: 'absolute',
    bottom: 40,
    left: '50%',
    transform: 'translateX(-50%)',
    display: 'flex',
    flexDirection: 'column',
    alignItems: 'center',
    zIndex: 10,
    gap: 10,
  }}>
    {subtitles.map(({ id, text, speaker }) => (
      <div
        key={id}
        style={{
          background: speaker === 'user' ? 'rgba(255,255,255,0.85)' : 'rgba(0,0,0,0.8)',
          color: speaker === 'user' ? '#000' : '#fff',
          padding: '16px 32px',
          borderRadius: 12,
          fontSize: 40,
          fontFamily: 'Roboto Medium, Roboto, sans-serif',
          fontWeight: 500,
          maxWidth: '90vw',
          textAlign: 'center',
          boxShadow: '0 2px 10px rgba(0,0,0,0.25)',
        }}
      >
        {text}
      </div>
    ))}
  </div>
);

const DisconnectButton = () => {
  const client = useRTVIClient();
  const transportState = useRTVIClientTransportState();
  const navigate = useNavigate();
  const [visible, setVisible] = useState(false);
  const isConnected = transportState === 'connected';

  return (
    <>
      <FloatButton
        icon={isConnected ? <PoweroffOutlined style={{ color: '#fff' }} /> : <LoadingOutlined style={{ color: '#ff4d4f' }} />}
        type="primary"
        className={isConnected ? 'float-btn-connected' : 'float-btn-disconnected'}
        style={{ top: 24, right: 24, zIndex: 9999, cursor: isConnected ? 'pointer' : 'default' }}
        onClick={() => isConnected && setVisible(true)}
      />
      {visible && (
        <div style={{ position: 'absolute', top: 80, right: 24, zIndex: 10000 }}>
          <Popconfirm
            title="Are you sure you want to disconnect?"
            open={visible}
            onConfirm={async () => {
              await client.disconnect();
              navigate('/');
            }}
            onCancel={() => setVisible(false)}
            okText="Yes"
            cancelText="No"
            placement="topRight"
            okButtonProps={{ danger: true }}
          />
        </div>
      )}
    </>
  );
};

interface BotVideoProps {
  cameraType: 'full_body' | 'half_body' | 'headshot';
  setCameraType: (t: any) => void;
  animationTrigger: string | null;
  setAnimationTrigger: (t: any) => void;
  currentViseme: number;
  interactionState: 'speaking' | 'listening' | null;
  onAvatarMounted?: () => void;
  videoFlag: boolean;
}

const BotVideo: React.FC<BotVideoProps> = ({
  cameraType,
  setCameraType,
  animationTrigger,
  setAnimationTrigger,
  currentViseme,
  interactionState,
  onAvatarMounted,
  videoFlag,
}) => {
  const [avatarUrl, setAvatarUrl] = useState<string | null>(null);
  const [showVideo, setShowVideo] = useState(false);
  const videoRef = useRef<HTMLVideoElement>(null);

  useEffect(() => {
    fetch('http://localhost:7860/avatar')
      .then(res => res.json())
      .then(data => {
        setAvatarUrl(data.avatar_url);
        onAvatarMounted?.();
      })
      .catch(err => console.error('Failed to fetch avatar:', err));
  }, [onAvatarMounted]);

  useRTVIClientEvent(
    RTVIEvent.TrackStarted,
    useCallback((track: MediaStreamTrack, participant?: Participant) => {
      if (participant?.local) return;
      if (track.kind === 'video') {
        if (videoRef.current) {
          videoRef.current.srcObject = new MediaStream([track]);
          setShowVideo(true);
        }
      }
    }, [])
  );

  if (!avatarUrl) return null;

  return (
    <div style={{ position: 'relative', width: '100vw', height: '100vh' }}>
      <AvatarRenderer
        avatarUrl={avatarUrl}
        bodyAnimation={animationTrigger}
        onAnimationEnd={() => {
          console.log('[AvatarRenderer] Animation ended â€” resetting trigger');
          setAnimationTrigger(null);
        }}
        cameraType={cameraType}
        currentViseme={currentViseme}
        interactionState={interactionState}
      />
      {videoFlag && (
        <video
          ref={videoRef}
          autoPlay
          muted
          playsInline
          style={{
            position: 'absolute',
            top: 20,
            left: 20,
            width: 320,
            height: 240,
            borderRadius: 16,
            backgroundColor: 'black',
            border: '1px solid black',
            zIndex: 6,
            boxShadow: '0 0 10px rgba(0,0,0,0.3)',
            opacity: showVideo ? 1 : 0,
            transition: 'opacity 0.3s ease-in-out',
          }}
        />
      )}
    </div>
  );
};

function AppContent() {
  const location = useLocation();
  const settingsUrl = location.state?.settingsUrl;
  const transportState = useRTVIClientTransportState();
  const client = useRTVIClient();
  const navigate = useNavigate();

  const [schema, setSchema] = useState<any | null>(null);
  const [formData, setFormData] = useState<any>({});
  const [interactionPhase, setInteractionPhase] = useState<'settings' | 'mounting' | 'ready'>('settings');
  const [cameraType, setCameraType] = useState<'full_body' | 'half_body' | 'headshot'>('headshot');
  const [animationTrigger, setAnimationTrigger] = useState<string | null>(null);
  const [currentViseme, setCurrentViseme] = useState<number>(0);
  const [interactionState, setInteractionState] = useState<'speaking' | 'listening' | null>(null);
  const [videoFlag, setVideoFlag] = useState<boolean>(false);
  const [subtitlesEnabled, setSubtitlesEnabled] = useState<{ user: boolean; bot: boolean }>({ user: true, bot: true });

  const [subtitleList, setSubtitleList] = useState<{ id: number, text: string, speaker: 'user' | 'bot' }[]>([]);
  const subtitleIdRef = useRef(0);
  const SUBTITLE_DURATION_MS = 5000;

  const visemeTimer = useRef<NodeJS.Timeout | null>(null);
  const startTimeRef = useRef<number | null>(null);
  const visemeBufferRef = useRef<{ duration: number; visemes: number[] }[]>([]);
  const usingRealVisemesRef = useRef(false);
  const timeoutHandlesRef = useRef<NodeJS.Timeout[]>([]);

  const clearAllTimeouts = useCallback(() => {
    timeoutHandlesRef.current.forEach(clearTimeout);
    timeoutHandlesRef.current = [];
  }, []);

  const scheduleVisemeBuffer = useCallback(() => {
    const buffer = visemeBufferRef.current;
    const t0 = startTimeRef.current!;
    const elapsed = performance.now() - t0;

    let acc = 0;
    let idx = 0;
    while (idx < buffer.length && acc + buffer[idx].duration * 1000 < elapsed) {
      acc += buffer[idx].duration * 1000;
      idx++;
    }
    if (idx >= buffer.length) return;

    const first = buffer[idx];
    setCurrentViseme(first.visemes[0]);

    const timeIntoFirst = elapsed - acc;
    let offset = first.duration * 1000 - timeIntoFirst;
    for (let j = idx + 1; j < buffer.length; j++) {
      const { duration, visemes } = buffer[j];
      const handle = setTimeout(() => {
        setCurrentViseme(visemes[0]);
      }, offset);
      timeoutHandlesRef.current.push(handle);
      offset += duration * 1000;
    }
    setCurrentViseme(0);
  }, []);

  const startRandomVisemeLoop = useCallback(() => {
    visemeTimer.current = setInterval(() => {
      setCurrentViseme(Math.floor(Math.random() * 22));
    }, 120);
  }, []);

  const stopRandomVisemeLoop = useCallback(() => {
    if (visemeTimer.current) {
      clearInterval(visemeTimer.current);
      visemeTimer.current = null;
    }
  }, []);

  const addSubtitle = useCallback((text: string, speaker: 'user' | 'bot') => {
    const id = subtitleIdRef.current++;
    setSubtitleList(prev => [...prev, { id, text, speaker }]);
    setTimeout(() => {
      setSubtitleList(prev => prev.filter(item => item.id !== id));
    }, SUBTITLE_DURATION_MS);
  }, []);

  useEffect(() => {
    if (!settingsUrl) return;
    const url = settingsUrl.startsWith('http') ? settingsUrl : `${window.location.origin}${settingsUrl}`;
    axios.get(url)
      .then(res => setSchema(res.data))
      .catch(err => console.error('Failed to load schema:', err));
  }, [settingsUrl]);

  useEffect(() => {
    if (interactionPhase === 'ready' && transportState === 'disconnected') {
      client.connect().catch(console.error);
    }
  }, [interactionPhase, transportState, client]);

  useRTVIClientEvent(RTVIEvent.BotStartedSpeaking, () => {
    console.log('Bot started speaking');
    startTimeRef.current = performance.now();
    usingRealVisemesRef.current = false;
    visemeBufferRef.current = [];
    clearAllTimeouts();
    setInteractionState('speaking');
    if (!animationTrigger) {
      console.log('No animation idle trigger');
      setAnimationTrigger('idle');
    } else {
      console.log('Animation idle trigger:', animationTrigger);
    }
    startRandomVisemeLoop();
  });

  useRTVIClientEvent(RTVIEvent.BotStoppedSpeaking, () => {
    console.log('Bot stopped speaking');
    startTimeRef.current = null;
    usingRealVisemesRef.current = false;
    visemeBufferRef.current = [];
    clearAllTimeouts();
    stopRandomVisemeLoop();
    setCurrentViseme(0);
    setInteractionState(null);
  });

  useRTVIClientEvent(RTVIEvent.UserStartedSpeaking, () => {
    console.log('User started speaking');
    setInteractionState('listening');
    if (!animationTrigger) {
      console.log('No animation idle trigger');
      setAnimationTrigger('idle');
    }  else {
      console.log('Animation idle trigger:', animationTrigger);
    }
  });

  useRTVIClientEvent(RTVIEvent.UserStoppedSpeaking, () => {
    console.log('User stopped speaking');
    setInteractionState(null);
  });

  useRTVIClientEvent(
    RTVIEvent.ServerMessage,
    useCallback((data: any) => {
      if (data.type === 'animation-event') {
        const { animation_id } = data.payload;
        setAnimationTrigger(animation_id);
      }
      if (data.type === 'visemes-event') {
        const payload = data.payload as { duration: number; visemes: number[] }[];
        visemeBufferRef.current.push(...payload);
        if (startTimeRef.current !== null) {
          if (!usingRealVisemesRef.current) {
            usingRealVisemesRef.current = true;
            stopRandomVisemeLoop();
          }
          clearAllTimeouts();
          scheduleVisemeBuffer();
        }
      }
    }, [setAnimationTrigger, clearAllTimeouts, stopRandomVisemeLoop, scheduleVisemeBuffer])
  );

  useRTVIClientEvent(RTVIEvent.UserTranscript, useCallback((data) => {
    if (data.final && subtitlesEnabled.user) {
      addSubtitle(data.text, 'user');
    }
  }, [subtitlesEnabled, addSubtitle]));

  useRTVIClientEvent(RTVIEvent.BotTranscript, useCallback((data) => {
    if (subtitlesEnabled.bot) {
      addSubtitle(data.text, 'bot');
    }
  }, [subtitlesEnabled, addSubtitle]));

  return (
    <div className="app">
      {interactionPhase === 'settings' && (
        <div style={{ maxWidth: 600, margin: '0 auto', padding: 20 }}>
          {schema && (
            <SettingsForm
              schema={schema}
              onSubmit={(values) => {
                setFormData(values);
                setCameraType(values.camera_settings);
                setVideoFlag(values.video_flag);
                setSubtitlesEnabled({ user: values.user_transcript, bot: values.bot_transcript });
                setInteractionPhase('mounting');
              }}
            />
          )}
        </div>
      )}

      {(interactionPhase === 'mounting' || interactionPhase === 'ready') && (
        <>
          <DisconnectButton />
          <BotVideo
            cameraType={cameraType}
            setCameraType={setCameraType}
            animationTrigger={animationTrigger}
            setAnimationTrigger={setAnimationTrigger}
            currentViseme={currentViseme}
            interactionState={interactionState}
            onAvatarMounted={() => {
              if (interactionPhase === 'mounting') {
                setInteractionPhase('ready');
              }
            }}
            videoFlag={videoFlag}
          />
          <SubtitleOverlay subtitles={subtitleList} />
        </>
      )}

      <RTVIClientAudio />
    </div>
  );
}

function App() {
  return (
    <RTVIProvider>
      <AppContent />
    </RTVIProvider>
  );
}

export default App;
